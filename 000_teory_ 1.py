import numpy as np
import pandas as pd

df = pd.read_csv('telecom.csv')
print(df.head()) # Выводим 5 первых строк таблицы
# print(df.shape) # Посмотрим на размер данных. Размерность таблицы n х m
# print(df.columns) # Выведем названия столбцов
# print(df.info()) # Общая информация по датафрейму и всем признакам

# Изменить тип колонки можно с помощью метода astype.
# Применим этот метод к признаку Churn и переведём его в int64
# df['churn'] = df['churn'].astype('int64')

# print(df.info())

# показывает основные статистические характеристики данных по каждому числовому признаку
# (типы int64 и float64): число непропущенных значений, среднее, стандартное отклонение,
# диапазон, медиану, 0.25 и 0.75 квартили.
# print(df.describe())


# Чтобы посмотреть статистику по нечисловым признакам, нужно явно указать интересующие нас
# типы в параметре include.
# print(df.describe(include=['object', 'bool']))
# print()

# Для категориальных (тип object) и булевых (тип bool) признаков можно воспользоваться методом
# value_counts. Посмотрим на распределение данных по нашей целевой переменной — Churn:
# print(df['churn'].value_counts())

# Посмотрим на распределение пользователей по переменной Area code. Укажем значение
# параметра normalize=True, чтобы посмотреть не абсолютные частоты, а относительные.
# print(df['area code'].value_counts(normalize=True))


### Сортировка

# DataFrame можно отсортировать по значению какого-нибудь из признаков. В нашем случае,
# например, по Total day charge (ascending=False для сортировки по убыванию):
# print(df.sort_values(by='total day charge', ascending=False).head())

# ортировать можно и по группе столбцов:
# df.sort_values(by=['churn', 'total day charge'], ascending=[True, False]).head()

### Индексация и извлечение данных

# DataFrame можно индексировать по-разному. В связи с этим рассмотрим различные
# способы индексации и извлечения нужных нам данных из датафрейма на примере простых вопросов.

# Для извлечения отдельного столбца можно использовать конструкцию вида DataFrame['Name'].
# Воспользуемся этим для ответа на вопрос: какова доля людей нелояльных пользователей в нашем датафрейме?

# print('Доля нелояльных клиентов', df['churn'].mean())

# Каковы средние значения числовых признаков среди нелояльных пользователей?
# print(df[df['churn'] == 1].mean())

# Сколько в среднем в течение дня разговаривают по телефону нелояльные пользователи
# print('Нелояльные разговаривают в день, мин', df[df['churn'] == 1]['total day minutes'].mean())
# print('Лояльные разговаривают в день, мин', df[df['churn'] == 0]['total day minutes'].mean())


# Какова максимальная длина международных звонков среди лояльных пользователей (Churn == 0),
# не пользующихся услугой международного роуминга ('International plan' == 'No')?

# print(df[(df['churn'] == 0) & (df['international plan'] == 'no')]['total intl minutes'].max())


    # Датафреймы можно индексировать как по названию столбца или строки, так и по порядковому номеру.
# Для индексации по названию используется метод loc, по номеру — iloc.
    # В первом случае мы говорим «передай нам значения для id строк от 0 до 5 и для столбцов от State
# до Area code», а во втором — «передай нам значения первых пяти строк в первых трёх столбцах».
# print(df.loc[0:5, 'state':'area code'])
# print()
# print(df.iloc[0:5, 0:3])

# Если нам нужна первая или последняя строчка датафрейма, пользуемся конструкцией df[:1] или df[-1:]:
# print(df[-1:])

### Применение функций к ячейкам, столбцам и строкам
# Применение функции к каждому столбцу: apply
# print(df.apply(np.max))

### Применение функции к каждой ячейке столбца: map

# Например, метод map можно использовать для замены значений в колонке, передав ему в качестве
# аргумента словарь вида {old_value: new_value}:
# d = {'no' : False, 'yes' : True}
# df['international plan'] = df['international plan'].map(d)
# print(df.head())

# Аналогичную операцию можно провернуть с помощью метода replace:
# df = df.replace({'voice mail plan': 'd'})
# print(df.head())

### Группировка данных
# В общем случае группировка данных в Pandas выглядит следующим образом:

# print(df.groupby(by=grouping_columns)[columns_to_show].function())

    # К датафрейму применяется метод groupby, который разделяет данные по
# grouping_columns – признаку или набору признаков.
    #Выбираем нужные нам столбцы (columns_to_show).
    # К полученным группам применяется функция или несколько функций.

### Группирование данных в зависимости от значения признака Churn и вывод статистик по трём столбцам в каждой группе.
# columns_to_show = ['total day minutes', 'total eve minutes', 'total night minutes']
# print(df.groupby(['churn'])[columns_to_show].describe(percentiles=[]))

# Сделаем то же самое, но немного по-другому, передав в agg список функций:
# columns_to_show = ['total day minutes', 'total eve minutes', 'total night minutes']
# print(df.groupby(['churn'])[columns_to_show].agg([np.mean, np.std, np.min, np.max]))

### Сводные таблицы
# Допустим, мы хотим посмотреть, как наблюдения в нашей выборке распределены в контексте
# двух признаков — Churn и International plan. Для этого мы можем построить таблицу
# сопряженности, воспользовавшись методом crosstab:
# print(pd.crosstab(df['churn'], df['international plan']))
# print()
# pd.crosstab(df['churn'], df['voice mail plan'], normalize=True)

# Мы видим, что большинство пользователей лояльны и при этом пользуются дополнительными услугами (международного роуминга / голосовой почты).

# Продвинутые пользователи Excel наверняка вспомнят о такой фиче, как сводные таблицы (pivot tables). В Pandas за сводные таблицы отвечает метод pivot_table, который принимает в качестве параметров:

# values – список переменных, по которым требуется рассчитать нужные статистики,
# index – список переменных, по которым нужно сгруппировать данные,
# aggfunc — то, что нам, собственно, нужно посчитать по группам — сумму, среднее, максимум, минимум или что-то ещё.

# Давайте посмотрим среднее число дневных, вечерних и ночных звонков для разных Area code:
# print(df.pivot_table(['total day calls', 'total eve calls', 'total night calls'], ['area code'], aggfunc='mean').head(10))

### Преобразование датафреймов
# Мы хотим посчитать общее количество звонков для всех пользователей. Создадим объект total_calls типа Series и вставим его в датафрейм:
# total_calls = df['total day calls'] + df['total eve calls'] + df['total night calls'] + df['total intl calls']
# df.insert(loc=len(df.columns), column='total calls', value=total_calls)
# # loc - номер столбца, после которого нужно вставить данный Series
# # мы указали len(df.columns), чтобы вставить его в самом конце
# print(df.head())

# Добавить столбец из имеющихся можно и проще, не создавая промежуточных Series:
# df['total charge'] = df['total day charge'] + df['total eve charge'] + df['total night charge'] + df['total intl charge']
# print(df.head())

# Чтобы удалить столбцы или строки, воспользуйтесь методом drop, передавая в качестве аргумента нужные индексы и требуемое
# значение параметра axis (1, если удаляете столбцы, и ничего или 0, если удаляете строки):
# избавляемся от созданных только что столбцов
# df = df.drop(['total charge', 'total calls'], axis=1)

# print(df.drop([1, 2]).head()) # а вот так можно удалить строчки

### Первые попытки прогнозирования оттока
# Посмотрим, как отток связан с признаком "Подключение международного роуминга" (International plan).
# Сделаем это с помощью сводной таблички crosstab, а также путем иллюстрации с Seaborn (как именно
# строить такие картинки и анализировать с их помощью графики – материал следующей статьи).
print(pd.crosstab(df['churn'], df['international plan'], margins=True))

# f =  open('output.txt', 'w')
# f.close()
#
# with open('output.txt', 'a') as file:
#     for line in df.sort_values(by='total day charge', ascending=False).head():
#         f = open('output.txt', 'a')
#         f.write(line + '\n')
#         f.close()